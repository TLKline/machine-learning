{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Lung Classification Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this course you will learn how to run a deep learning experiment - from loading data, running a model, and deploying your model on a test dataset.\n",
    "\n",
    "This course will build upon the knowledge gained in the first lesson and will utilize a much larger dataset.\n",
    "\n",
    "In this course you will build a deep learning model that identifies whether an x-ray of the lungs contains an opacity. The dataset is from a Kaggle challenge.\n",
    "\n",
    "The dataset comes from the RSNA Pneumonia Detection Challenge (Kaggel API)\n",
    "        ,\n",
    "        \"The [Radiological Society of North America](http://www.rsna.org/) Pneumonia Detection Challenge: https://www.kaggle.com/c/rsna-pneumonia-detection-challenge\",\n",
    "\n",
    "\n",
    "<img src=\"images/lesson2_datasetImage.png\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include the mdai module, output current mdai version\n",
    "!pip install -q --upgrade mdai\n",
    "import mdai\n",
    "mdai.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add mdai client\n",
    "mdai_client = mdai.Client(domain='public.md.ai', access_token=\"ENTER ACCESS TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = mdai_client.project('LxR6zdR2', path='./lung-opacity-data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.show_label_groups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this maps label ids to class ids as a dict obj\n",
    "labels_dict = {'L_ylR0L8':0, # No Lung Opacity \n",
    "               'L_DlqEAl':1, # Lung Opacity  \n",
    "              }\n",
    "\n",
    "print(labels_dict)\n",
    "p.set_labels_dict(labels_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show dataset ID and label mappings\n",
    "p.show_datasets() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display label classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = p.get_dataset_by_id('D_ao3XWQ')\n",
    "dataset.prepare()\n",
    "dataset.show_classes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anns = dataset.get_annotations()\n",
    "\n",
    "while 0:\n",
    "    # create training dataset \n",
    "    train_dataset = p.get_dataset_by_name('TRAIN')\n",
    "    train_dataset.prepare() \n",
    "    train_image_ids = train_dataset.get_image_ids()\n",
    "    print(len(train_image_ids))\n",
    "\n",
    "\n",
    "    # create the validation dataset \n",
    "    val_dataset = p.get_dataset_by_name('VAL')\n",
    "    val_dataset.prepare()\n",
    "    val_image_ids = val_dataset.get_image_ids()\n",
    "    print(len(val_image_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = mdai.common_utils.train_test_split(dataset, validation_split = 0.98)\n",
    "val_dataset, test_dataset = mdai.common_utils.train_test_split(val_dataset, validation_split = 0.995)\n",
    "test_dataset, test_dataset2 = mdai.common_utils.train_test_split(test_dataset, validation_split = 0.90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anns = dataset.get_annotations(labels_dict.keys(), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_ids = train_dataset.get_image_ids()\n",
    "val_image_ids = val_dataset.get_image_ids()\n",
    "\n",
    "# visualize a few train images \n",
    "mdai.visualize.display_images(train_image_ids[:2], cols=2)\n",
    "mdai.visualize.display_images(val_image_ids[:2], cols=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# get image pixel data\n",
    "pixel_array = mdai.visualize.load_dicom_image(train_image_ids[0], to_RGB=False, rescale=True)\n",
    "print(np.shape(pixel_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import keras module\n",
    "from keras import applications\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dropout, Flatten, Dense, GlobalAveragePooling2D, Conv2D\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model parameters \n",
    "img_width = 128\n",
    "img_height = 128\n",
    "epochs = 20\n",
    "\n",
    "params = {\n",
    "    'dim': (img_width, img_height),\n",
    "    'batch_size': 8,\n",
    "    'n_classes': 2,\n",
    "    'n_channels': 3,\n",
    "    'shuffle': True,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Begin Defining Model\n",
    "\n",
    "Here we build up a very basic CNN architecture (similar in nature to the VGG class of architectures).\n",
    "\n",
    "Here is where you can feel free to experiment with different architectures and tune the hyperparameters of the network. You should observe differences in training performance, as well as the amount of time required to fully train the network. \n",
    "\n",
    "Try changing the number of kernels in the network from 32 down to 16.\n",
    "\n",
    "For example:\n",
    "\n",
    "```python\n",
    "conv1 = Conv2D(16, (3,3), activation = 'relu', padding='same')(inputs)\n",
    "```\n",
    "\n",
    "Or changing the size of the filter kernels from 3x3 to 5x5\n",
    "\n",
    "```python\n",
    "conv1 = Conv2D(32, (5,5), activation = 'relu', padding='same')(inputs)\n",
    "```\n",
    "\n",
    "Or the activation function for the output:\n",
    "\n",
    "```python\n",
    "conv1 = Conv2D(32, (3,3), activation = 'tanh', padding='same')(inputs)\n",
    "```\n",
    "\n",
    "How do these parameters affect performance and training time?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Begin Defining Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test1 = False\n",
    "\n",
    "# CNN example\n",
    "if model_test1 is True:\n",
    "    # Create a basic CNN architecture\n",
    "\n",
    "    inputs = Input((img_width, img_height, 3))\n",
    "\n",
    "    # Block1\n",
    "    conv1 = Conv2D(32, (3,3), activation = 'relu', padding='same')(inputs)\n",
    "    conv2 = Conv2D(32, (3,3), activation = 'relu', padding='same')(conv1)\n",
    "    max1 = MaxPooling2D((4,4), strides = (4,4))(conv2)\n",
    "\n",
    "    # Block2\n",
    "    conv3 = Conv2D(64, (3,3), activation = 'relu', padding='same')(max1)\n",
    "    conv4 = Conv2D(64, (3,3), activation = 'relu', padding='same')(conv3)\n",
    "    max2 = MaxPooling2D((4,4), strides = (4,4))(conv4)\n",
    "\n",
    "    fcn = Flatten()(max2)\n",
    "    fcn = Dense(512,activation='relu')(fcn) # was 1028\n",
    "    fcn = Dropout(0.5)(fcn)\n",
    "    fcn = Dense(256,activation='relu')(fcn) # was 512\n",
    "    fcn = Dropout(0.5)(fcn)\n",
    "    output = Dense(2,activation='softmax')(fcn)\n",
    "\n",
    "    model = Model(inputs,output)\n",
    "\n",
    "    model.compile(optimizer=Adam(lr=5.E-6, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0), \n",
    "                  loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# transfer learning example\n",
    "if model_test1 is False:\n",
    "    base_model = applications.mobilenet.MobileNet(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
    "\n",
    "    model_top  = Sequential()\n",
    "    model_top.add(GlobalAveragePooling2D(input_shape=base_model.output_shape[1:], data_format=None))\n",
    "    model_top.add(Dense(256, activation='relu'))\n",
    "    model_top.add(Dropout(0.5))\n",
    "    model_top.add(Dense(2, activation='softmax')) \n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=model_top(base_model.output))\n",
    "\n",
    "    model.compile(optimizer=Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08,decay=0.0), \n",
    "                  loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End Defining Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mdai.utils import keras_utils\n",
    "\n",
    "train_generator = keras_utils.DataGenerator(train_dataset, **params)\n",
    "val_generator = keras_utils.DataGenerator(val_dataset, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "config = tf.compat.v1.ConfigProto() #update for tf2 compatibility\n",
    "config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set callback functions to early stop training and save the best model so far\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=4, verbose=2),\n",
    "    ModelCheckpoint(filepath='best_model_lesson2.h5', monitor='val_acc', \n",
    "                    save_best_only=True, verbose=2)\n",
    "]\n",
    "\n",
    "history = model.fit_generator(\n",
    "            generator=train_generator,\n",
    "            epochs=epochs,\n",
    "            callbacks=callbacks,\n",
    "            verbose=1,            \n",
    "            validation_data=val_generator,\n",
    "            use_multiprocessing=False,\n",
    "            workers=8)             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(history.history.keys())\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history.history['accuracy'], 'orange', label='Training accuracy')\n",
    "plt.plot(history.history['val_accuracy'], 'blue', label='Validation accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch', fontsize=16)\n",
    "plt.ylabel('Accuracy', fontsize = 16)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'], 'red', label='Training loss')\n",
    "plt.plot(history.history['val_loss'], 'green', label='Validation loss')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch', fontsize=16)\n",
    "plt.ylabel('Loss', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('best_model_lesson2.h5')\n",
    "test_dataset.prepare()\n",
    "print(len(test_dataset.image_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#from skimage.transform import resize\n",
    "from PIL import Image \n",
    "\n",
    "for image_id in test_dataset.image_ids[80:100]: \n",
    "    \n",
    "    image = mdai.visualize.load_dicom_image(image_id, to_RGB=True)\n",
    "    image = Image.fromarray(image)\n",
    "    image = image.resize((img_width, img_height))\n",
    "    \n",
    "    x = np.expand_dims(image, axis=0)    \n",
    "    y_prob = model.predict(x) \n",
    "    y_classes = y_prob.argmax(axis=-1)\n",
    "    \n",
    "    title = 'Pred: ' + test_dataset.class_id_to_class_text(y_classes[0]) + ', Prob:' + str(round(y_prob[0][y_classes[0]], 3))\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------ Activation Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, ZeroPadding2D, MaxPooling2D\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras import backend as K\n",
    "import h5py\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "def global_average_pooling(x):\n",
    "    return K.mean(x, axis = (2,3))\n",
    "\n",
    "def global_average_pooling_shape(input_shape):\n",
    "    return input_shape[0:2]\n",
    "\n",
    "def VGG_like_convolutions():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(ZeroPadding2D((1,1),input_shape=(128,128,3)))\n",
    "    model.add(Convolution2D(16, (3, 3), activation='relu', name='conv1_1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(16, (3, 3), activation='relu', name='conv1_2'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(32, (3, 3), activation='relu', name='conv2_1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(32, (3, 3), activation='relu', name='conv2_2'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "    \n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(64, (3, 3), activation='relu', name='conv3_1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(64, (3, 3), activation='relu', name='conv3_2'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "    \n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(128, (3, 3), activation='relu', name='conv4_1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(128, (3, 3), activation='relu', name='conv4_2'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    return model\n",
    "\n",
    "def get_model_vgg_like():\n",
    "    model = VGG_like_convolutions()\n",
    "    \n",
    "    model.add(Lambda(global_average_pooling, \n",
    "              output_shape=global_average_pooling_shape))\n",
    "    model.add(Dense(2, activation = 'softmax', kernel_initializer='uniform'))\n",
    "    sgd = SGD(lr=0.001, decay=1e-6, momentum=0.5, nesterov=True)\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = sgd, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def get_output_layer(model, layer_name):\n",
    "    # get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
    "    layer_dict = dict([(layer.name, layer) for layer in model.layers])\n",
    "    layer = layer_dict[layer_name]\n",
    "    return layer\n",
    "\n",
    "model = get_model_vgg_like()\n",
    "\n",
    "# Set callback functions to early stop training and save the best model so far\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=3, verbose=2),\n",
    "    ModelCheckpoint(filepath='best_model_am2.h5', monitor='val_loss', \n",
    "                    save_best_only=True, verbose=2)\n",
    "]\n",
    "\n",
    "history = model.fit_generator(\n",
    "            generator=train_generator,\n",
    "            epochs=epochs,\n",
    "            callbacks=callbacks,\n",
    "            verbose=1, #on a Windows machine you may want to use verbose=0           \n",
    "            validation_data=val_generator,\n",
    "            use_multiprocessing=False,\n",
    "            workers=4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def get_output_layer(model, layer_name):\n",
    "    # get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
    "    layer_dict = dict([(layer.name, layer) for layer in model.layers])\n",
    "    layer = layer_dict[layer_name]\n",
    "    return layer\n",
    "\n",
    "def visualize_class_activation_map(model, img):\n",
    "    model = model\n",
    "    original_img = img\n",
    "    width = 128\n",
    "    height = 128\n",
    "\n",
    "    #Get the 512 input weights to the softmax.\n",
    "    class_weights = model.layers[-1].get_weights()[0]\n",
    "    final_conv_layer = get_output_layer(model, \"conv4_2\")\n",
    "    get_output = K.function([model.layers[0].input], \\\n",
    "        [final_conv_layer.output, \n",
    "    model.layers[-1].output])\n",
    "    [conv_outputs, predictions] = get_output([np.float32(img)])\n",
    "    \n",
    "    conv_outputs = conv_outputs[0, :, :, :]\n",
    "    \n",
    "    #Create the class activation map.\n",
    "    cam = np.zeros(dtype = np.float32, shape = conv_outputs.shape[0:2])\n",
    "    for i, w in enumerate(class_weights[:, 1]):\n",
    "            cam += w * conv_outputs[:, :, i]\n",
    "    #print(\"predictions\", predictions)\n",
    "\n",
    "    cam = cv2.resize(cam, (height, width))\n",
    "\n",
    "    return cam\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image \n",
    "\n",
    "for image_id in test_dataset.image_ids[80:100]: \n",
    "    \n",
    "    image = mdai.visualize.load_dicom_image(image_id, to_RGB=True)\n",
    "    image = Image.fromarray(image)\n",
    "    image = image.resize((img_width, img_height))\n",
    "    \n",
    "    x = np.expand_dims(image, axis=0)    \n",
    "    y_prob = model.predict(x) \n",
    "    y_classes = y_prob.argmax(axis=-1)\n",
    "    \n",
    "    title = 'Pred: ' + test_dataset.class_id_to_class_text(y_classes[0]) + ', Prob:' + str(round(y_prob[0][y_classes[0]], 3))\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    plt.imshow(image, cmap='jet')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Add the activation map overlay\n",
    "    cam = visualize_class_activation_map(model, x)\n",
    "    cam = cam - np.min(cam)\n",
    "    cam[cam<np.max(cam)/2]=0\n",
    "    masked = np.ma.masked_where(cam == 0, cam)\n",
    "    plt.imshow(masked,cmap='jet',alpha=0.3)\n",
    "    plt.axis('off')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate learning curves for this final network\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(history.history.keys())\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history.history['accuracy'], 'orange', label='Training accuracy')\n",
    "plt.plot(history.history['val_accuracy'], 'blue', label='Validation accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch', fontsize=16)\n",
    "plt.ylabel('Accuracy', fontsize = 16)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'], 'red', label='Training loss')\n",
    "plt.plot(history.history['val_loss'], 'green', label='Validation loss')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch', fontsize=16)\n",
    "plt.ylabel('Loss', fontsize=16)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}